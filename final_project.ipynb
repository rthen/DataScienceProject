{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Preface\n",
    "\n",
    "The city of Boston has created an initiate on making different datasets available to the public. These datasets cover different aspect of the city of Boston such as City Hall electricity usage, approved building permits, and 311 service requests. For this project, I will be focusing on the crime reported to the Boston Police Department (BPD). The end goal is to provide some insight of the crimes within Boston, assisting the BPD to better prepare for crimes. \n",
    "\n",
    "There are two reasons to why I chose this dataset:\n",
    "-  Concurrent updates: The dataset covers crimes from 2015 until April of 2019 (as of writing of this notebook). The dataset is constantly updated as new crimes occurred\n",
    "-  Dataset features: This dataset contains enough features that can assist with different analysis. The data has also been carefully sanitized before making it public, easing the tasks of analyzing the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "These libraries must be present prior to running the notebook.\n",
    "For more information, please visit the developer site for each package.\n",
    "'''\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gmaps\n",
    "import plotly as py\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go \n",
    "import requests\n",
    "import matplotlib as plt\n",
    "import sklearn\n",
    "\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"Seaborn version: {sns.__version__}\")\n",
    "print(f\"gmaps version: {gmaps.__version__}\")\n",
    "print(f\"Plotly version: {py.__version__}\")\n",
    "print(f\"requests version: {requests.__version__}\")\n",
    "print(f\"matplotlib version: {plt.__version__}\")\n",
    "print(f\"sklearn version: {sklearn.__version__}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the crime data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacrime_api = \"https://data.boston.gov/datastore/dump/12cb3883-56f5-47de-afa5-3b1cf61b257b\"\n",
    "api_response = requests.get(datacrime_api)\n",
    "if (api_response.status_code == 200):\n",
    "    crime_data = pd.read_csv(datacrime_api, parse_dates=['OCCURRED_ON_DATE'])\n",
    "    print(\"Retrieval of dataset from Analyze Boston's API was succesful\")\n",
    "else:\n",
    "    print(f\"The notebook could not connect to the API. The following error has ocurred: {api_response}.\")\n",
    "    print(\"Instead, the notebook will use a local dataset retrieved on April 7, 2019.\")\n",
    "    crime_data = pd.read_csv(\"tmpj29on4xs.csv\", parse_dates=['OCCURRED_ON_DATE'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this notebook, I will be concentrating on different features to find patterns and answer some questions about this data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting crimes in districts\n",
    "Sometimes BPD is not able to accurately determine the location of crimes in the city of Boston. By using the Sickit's API, we might be able to do some sort of prediction on which ditricts crime will occur based on certain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidCrimeData = crime_data.loc[crime_data[\"DISTRICT\"].notnull() & crime_data[\"STREET\"].notnull() & crime_data[\"UCR_PART\"].notnull()]\n",
    "\n",
    "x = ValidCrimeData[[\"OFFENSE_CODE\", \"MONTH\", \"HOUR\"]]\n",
    "\n",
    "y = ValidCrimeData[\"DISTRICT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "pd.set_option('mode.chained_assignment', None) # Hides warning about chainning\n",
    "\n",
    "LabelEncoder = LabelEncoder()\n",
    "\n",
    "street = ValidCrimeData[\"STREET\"]\n",
    "StreetEnc = LabelEncoder.fit_transform(street)\n",
    "x[\"STREET\"] = StreetEnc\n",
    "\n",
    "ReportingArea = ValidCrimeData[\"REPORTING_AREA\"]\n",
    "ReportingAreaEnc = LabelEncoder.fit_transform(ReportingArea)\n",
    "x[\"REPORTING_AREA\"] = ReportingAreaEnc\n",
    "\n",
    "IncidentNum = ValidCrimeData[\"INCIDENT_NUMBER\"]\n",
    "IncidentNumEnc = LabelEncoder.fit_transform(IncidentNum)\n",
    "x[\"INCIDENT_NUMBER\"] = IncidentNumEnc\n",
    "\n",
    "OffenseDescreption = ValidCrimeData[\"OFFENSE_DESCRIPTION\"]\n",
    "OffenseDescreptionEnc = LabelEncoder.fit_transform(OffenseDescreption)\n",
    "x[\"OFFENSE_DESCRIPTION\"] = OffenseDescreptionEnc\n",
    "\n",
    "OffenseCode = ValidCrimeData[\"OFFENSE_CODE_GROUP\"]\n",
    "OffenseCodeEnc = LabelEncoder.fit_transform(OffenseCode)\n",
    "x[\"OFFENSE_CODE_GROUP\"] = OffenseCodeEnc\n",
    "\n",
    "DayOfWeek = ValidCrimeData[\"DAY_OF_WEEK\"]\n",
    "DayOfWeekEnc = LabelEncoder.fit_transform(DayOfWeek)\n",
    "x[\"DAY_OF_WEEK\"] = DayOfWeekEnc\n",
    "\n",
    "UrcPart = ValidCrimeData[\"UCR_PART\"]\n",
    "UrcPartENC = LabelEncoder.fit_transform(UrcPart)\n",
    "x[\"URCPart\"] =  UrcPartENC\n",
    "\n",
    "occurred_data = ValidCrimeData[\"OCCURRED_ON_DATE\"]\n",
    "OccurredDataEnc = LabelEncoder.fit_transform(occurred_data)\n",
    "x[\"OCCURRED_ON_DATE\"] = OccurredDataEnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# KNeighborsClassifier = 0.2575589894932437\n",
    "# SVC\n",
    "model = GaussianNB()\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(x, y, test_size=.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtrain, Ytrain) # Fit model to data\n",
    "y1_model = model.predict(Xtrain) # Predict on new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Ytrain, y1_model) # View score of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_model = model.predict(Xtest) # View score of test train data\n",
    "accuracy_score(Ytest, y2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we provide a quick overview of crimes to BPD? One of the easiest way is to find the top crimes for the available dataset. In this case, I will be focusing on the top 20 crimes from 2015 to the most present time, which is April of 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "top_20_crimes = pd.DataFrame(crime_data[\"OFFENSE_DESCRIPTION\"].value_counts()[:20]) # Select top 20 crimes 2015-2019\n",
    "sns.set(style=\"darkgrid\", rc={'figure.figsize':(10,10)})\n",
    "ax = sns.barplot(x=top_20_crimes[\"OFFENSE_DESCRIPTION\"], y=top_20_crimes.index, data=top_20_crimes)\n",
    "ax.set_xlabel('Total crimes',x=0.4, fontsize=20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to begin by looking at the trend of crimes from 2015 until April of 2019. Primarily, we are focusing on the fluctuaction of crimes for the months of January through December for the years previously mentioned. To start, we will be collecting all crimes for all the years available within the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select year column\n",
    "crime2015 = crime_data.loc[crime_data[\"YEAR\"] == 2015]\n",
    "crime2016 = crime_data.loc[crime_data[\"YEAR\"] == 2016]\n",
    "crime2017 = crime_data.loc[crime_data[\"YEAR\"] == 2017]\n",
    "crime2018 = crime_data.loc[crime_data[\"YEAR\"] == 2018]\n",
    "crime2019 = crime_data.loc[crime_data[\"YEAR\"] == 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our data will be out of order, causing our graph to improperly display data. To solve this, we need to first count all the crimes for each individual month on the available years. Then, we will map the indexes of the crime data to match a Pandas series that will contain the name of the months. The mapping will allow us to map the month number to the month name. Lastly, we want to re-index the series' indexing. This will set the order of the months in the proper order. Additionally, any values missing on certain months, the re-indexing will simply fill NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts all crimes for each year and month, then sorts index from smallest to largest (index = month number)\n",
    "months = pd.Series([\"\", \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"])\n",
    "\n",
    "crime2015_count = (crime2015[\"MONTH\"]).map(months).value_counts().reindex(months)\n",
    "crime2016_count = (crime2016[\"MONTH\"]).map(months).value_counts().reindex(months)\n",
    "crime2017_count = (crime2017[\"MONTH\"]).map(months).value_counts().reindex(months)\n",
    "crime2018_count = (crime2018[\"MONTH\"]).map(months).value_counts().reindex(months)\n",
    "crime2019_count = (crime2019[\"MONTH\"]).map(months).value_counts().reindex(months)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize our data, we can use many different tools such as matplotlib, seaborn, etc. However, none of them offered an easy\n",
    "way for someone to interact with the data such as changing the year to view crimes. For such task, I will be implementing \n",
    "a volume chart with plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "pip install plotly \n",
    "pip install dash==0.39.0  # The core dash backend\n",
    "\n",
    "####### This gets installed when installing dash #######\n",
    "pip install dash-html-components==0.14.0  # HTML components\n",
    "pip install dash-core-components==0.44.0  # Supercharged components\n",
    "pip install dash-table==3.6.0  # Interactive DataTable component (new!)\n",
    "\n",
    "####### This does not get installed when installing dash, will need to run pip #######\n",
    "pip install dash-daq==0.1.0  # DAQ components (newly open-sourced!)\n",
    "'''\n",
    "\n",
    "tools.set_credentials_file(username=\"thenr@wit.edu\",api_key=\"aEjbCknbrip24nS2D45f\")\n",
    "# Defines x/y axis as well as style\n",
    "crime2019_plot = go.Scatter(x=(crime2019_count.index),\n",
    "    y=crime2019_count.values,\n",
    "    name=\"2019\",\n",
    "    line=dict(color='#ce1c1c')\n",
    ")\n",
    "\n",
    "crime2018_plot = go.Scatter(x=(crime2018_count.index),\n",
    "    y=crime2018_count.values,\n",
    "    name=\"2018\",\n",
    "    line=dict(color='#2ae011')\n",
    ")\n",
    "\n",
    "crime2017_plot = go.Scatter(x=(crime2017_count.index), #crime2017_count.index,\n",
    "    y=crime2017_count.values,\n",
    "    name=\"2017\",\n",
    "    line=dict(color='#1025e0')\n",
    ")\n",
    "\n",
    "crime2016_plot = go.Scatter(x=(crime2016_count.index), #crime2016_count.index,\n",
    "    y=crime2016_count.values,\n",
    "    name=\"2016\",\n",
    "    line=dict(color='#10e0c7')\n",
    ")\n",
    "\n",
    "crime2015_plot = go.Scatter(x=(crime2015_count.index), #crime2015_count.index,\n",
    "    y=crime2015_count.values,\n",
    "    name=\"2015\",\n",
    "    line=dict(color='#fffb0f')\n",
    ")\n",
    "\n",
    "\n",
    "data = [crime2019_plot, crime2018_plot, crime2017_plot, crime2016_plot, crime2015_plot]\n",
    "\n",
    "updatemenus = list([\n",
    "    dict(active=-1,\n",
    "         buttons=list([\n",
    "             dict(label = '2015 to 2019',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [True, True, True, True, True]}, # Defines which dataframe to display per plot\n",
    "                         {'title': 'Crimes report from 2015 to 2019',\n",
    "                          'annotations': data}]), \n",
    "             dict(label = '2019',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [True, False, False, False, False]},\n",
    "                         {'title': 'Crimes of 2019',\n",
    "                          'annotations': crime2019_plot}]), \n",
    "             dict(label = '2018',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False, True, False, False, False]},\n",
    "                         {'title': 'Crimes of 2018',\n",
    "                          'annotations': crime2018_plot}]),         \n",
    "            dict(label = '2017',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False, False, True, False, False]},\n",
    "                         {'title': 'Crimes of 2017',\n",
    "                          'annotations': crime2017_plot}]),         \n",
    "            dict(label = '2016',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False, False, False, True, False]},\n",
    "                         {'title': 'Crimes of 2016',\n",
    "                          'annotations': crime2016_plot}]),\n",
    "             dict(label = '2015',\n",
    "                 method = 'update',\n",
    "                 args = [{'visible': [False, False, False, False, True]},\n",
    "                         {'title': 'Crimes of 2015',\n",
    "                          'annotations': crime2015_plot}])         \n",
    "        ]),\n",
    "    )\n",
    "])\n",
    "\n",
    "layout = dict(title='Crimes report from 2015 to 2019', showlegend=True, updatemenus=updatemenus)\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.plotly.iplot(fig, filename='update_dropdown')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montly crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = (pd.DataFrame((crime_data[[\"OFFENSE_CODE\"]]).set_index(crime_data[\"OCCURRED_ON_DATE\"]))).index.month\n",
    "MonthsName = pd.Series([\"\", \"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"])\n",
    "monthsanalysis = months.map(MonthsName).value_counts().reindex(MonthsName)\n",
    "\n",
    "bar_chart = plt.pyplot.bar(x=monthsanalysis.index, height=monthsanalysis.values, color=\"orange\")\n",
    "plt.pyplot.xticks(rotation=45)\n",
    "\n",
    "\n",
    "plt.pyplot.plot((monthsanalysis.values), 'r--o') # Line over bar chart\n",
    "plt.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day of the week crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweek = (pd.DataFrame((crime_data[[\"OFFENSE_CODE\"]]).set_index(crime_data[\"OCCURRED_ON_DATE\"]))).index.dayofweek\n",
    "WeekdaysName = pd.Series([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "dayofweekname = dayofweek.map(WeekdaysName).value_counts().reindex(WeekdaysName)\n",
    "\n",
    "bar_chart = plt.pyplot.bar(x=dayofweekname.index, height=dayofweekname.values)\n",
    "\n",
    "plt.pyplot.plot((dayofweekname.values), 'r--o') # Line over bar chart\n",
    "plt.pyplot.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location of crimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset contains the coordinates of where reported crimes ocurred, it would be ideal to have a visualization of such crimes. To do so, we will be using gmaps. gmaps is an opensource module that integrates well with Jupyter. For more information, please visit: https://github.com/pbugnion/gmaps.\n",
    "\n",
    "Before using gmaps, you will need to obtain an API key from Google maps: https://developers.google.com/maps/documentation/javascript/get-api-key. Once you have obtained the key, you can use it by setting gmaps.configure(api_key=\"\") equals to your key. One of the advantages of using your own key is the availability of looking at the analytics of the API calls:\n",
    "\n",
    "![title](url=\"https://drive.google.com/file/d/1gEnFeiTBxLSonw-FU86rzMNm66ec2TPN/view?usp=sharing\")\n",
    "\n",
    "However, for simplicity, the key is already provided in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1-Install gmaps by running conda install -c conda-forge gmaps\n",
    "\n",
    "2-Enable ipywidgets extensions by running jupyter nbextension enable --py --sys-prefix widgetsnbextension\n",
    "\n",
    "3-Load the extension to jupy by running jupyter nbextension enable --py --sys-prefix gmaps\n",
    "\n",
    "4-Next, let's install the jupyter widgets extension for JupyterLab by running jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "If you receive an error that node js is not installed, run \"conda install nodejs\". Then re-run the labextension installtion\n",
    "\n",
    "5-Next, run \"jupyter lab build\" to rebuild jupyterlab in order to incolde the frontend code to jupyerlab installtion. Next\n",
    "Restart the kernel and try again. \n",
    "\n",
    "'''\n",
    "\n",
    "gmaps.configure(api_key=\"AIzaSyCHGv8iQ0fuxUnIccKCwcMnHepRMeBo85Y\")\n",
    "\n",
    "#####################################################################################################\n",
    "# Certain crimes reported to BPD does not contain location. Instead, BPD sets latitute and longtitute \n",
    "# equals to 0.000000. Since these coordinates are not useful, let's drop them\n",
    "#####################################################################################################\n",
    "crime_lat_long = crime_data[[\"Lat\", \"Long\"]].dropna()\n",
    "\n",
    "# Create a heatmap using coordinates on Google maps\n",
    "fig = gmaps.figure()\n",
    "heatmap_layer = gmaps.heatmap_layer(crime_lat_long)\n",
    "\n",
    "fig.add_layer(heatmap_layer)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While zooming in the Boston area with Google maps, you may have noticed that the heatmap slowly disappears as you zoom into the city. This is due to Google maps trimming off the maximum peak intensity of the points. To get around this, we need to modify the max_intensity and the point_radius of the heatmap. Unfortunately, there is no perfect value for these settings. The best way to find a decent value is by playing around with gmap's settings. For the dataset we are using, I discovered that max_intensity = 100 and point_radius = 12 works best. Rather than re-drawing the heat map, we are able to modify these settings and only change the coverage of each individual point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_layer.max_intensity = 100\n",
    "heatmap_layer.point_radius = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you zoom out, you will see the heatmap covers a large portion of the Boston city. However, when zooming in, you will begin to see the heatmap properly display the dataset's coordinates. Again, this is just the way Google maps handles the drawing of the heatmap and not a bug with gmaps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were many challenges that I faced when working in this project. For starters, picking a dataset. In today's age, there hundreds of datasets available. I struggle on choosing one as I wanted to work on something that will be interesting and also use a dataset that I could trust. Additionally, what type of analysis I wanted to carry out was another challenge. In this dataset, I could either do regression or classification. After doing research and understanding what exactly I wanted to do, I decided to move towards classifying whether a crime occurs in a certain district within the city of Boston. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implement graphs and heatmap on a public site\n",
    "- Increase the score of predicting the likelyhood of a crime ocurring in a district\n",
    "- Do some regression to predict how many crimes are likely to occur in a given month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "With this dataset, we were able to answer some questions and find some patterns about crimes within the city of Boston. We discovered the most common crimes committed, where crimes occurred, and more. With existing tools, data analysis could not be any easier. What makes these tools so powerful is the opportunity to apply many of the same logic with different datasets. This can allow us to answer questions with unknown answers or have a better understanding of existing data. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
